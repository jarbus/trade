29d9b: reward for every living player, one shared policy
aef2e: reward for every living player, each agent has unique policy
c7ad4: reward just for personal survival, each agent has unique policy
db5b4: reward is a mix of other survival and self survival

-----change reward----
reward = 1 + empathy * num_living_players
c7c56: empathy is varied across samples, 0->1
11b2c: empathy is varied across samples, 0->2, and got rid of minibatches
efb20: empathy is varied across samples, 0->.5, maximize episode len instead of reward, brought back mini batches
1d3cf: empathy 0->2, disabled pbt (just tryring random hparams) maximize episode len instead of reward <- shouldn't affect anything

----params---
f7e92: more params (512x5), 8000 batch, pbt works
33a41: more params (512x5), 8000 batch, works again
7953f: lower cognitive capacity (64x3), 8000 batch, trades a lot less (episode reward is less than 20)
a8971:  (512x5), 4000 batch, remove empathy?  <------running

Custom names:
-------------
VaryBatch: 512x5, no pdt, batch 4000 empathy 0.1. failure
           Note: this is called varybatch
Batch 8000: Batch 8000, no PBt, empathy 1, 512x5 
           Experiment to see if pbt is necessary
           All trials except 1 fail
More Samples* : "32 Samples, Batch 8000, No PBT, Empathy 2, 512x5" 
        Trials seem to take much longer than without pbt.

5m Steps, 16 samples, PBT
--------------------
Batch 8k
    Empathy 0: fails to trade
    Empathy 0.1:
    Empathy 1:

Empathy 1
    Batch Size 100, 1k, 4k, 8k
    Batch size 100 has more variance, but smaller 
    batch size leads to faster training. 512 should be fine rn
 
No PBT, 5m steps, 16 samples, 500 batch
--------------------


--- next ----

Theory: pbt allows a single success to propogate to other runs, (duh),
and smaller networks are less likely to find the winning solution at all,
so it's a cointoss on whether a single network finds the trading solution.
If we use larger networks, we should be good.

future areas:
explore centralized critic <-- see if this can be avoided

---- Findings -----
* pbt makes or breaks this system, empathy of 2 makes this system take an incredibly long time without pbt
  some trials still succeed with a smaller batch size 
* empathy directly impacts the speed at which agents learn to trade
* lower train batch leads to faster learning, variance seems to be managable with batch sizes 1000+
